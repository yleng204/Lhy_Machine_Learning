{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03/09/2021 ECHR Binary Multilingual BERT: AIjudge with XLM-Roberta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yleng204/Lhy_Machine_Learning/blob/main/03_09_2021_ECHR_Binary_Multilingual_BERT_AIjudge_with_XLM_Roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9ZiBy6HsbsK",
        "outputId": "dd6f7ca1-60be-4af8-f3fe-67d047fc690c"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.16)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiPf4Y_VrnwH",
        "outputId": "4377007f-73f8-44a7-c849-5fd054f7b86d"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"ecthr_cases\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: ecthr_cases/alleged-violation-prediction\n",
            "Reusing dataset ecthr_cases (/root/.cache/huggingface/datasets/ecthr_cases/alleged-violation-prediction/1.1.0/8922a012792758e64921d4a66d42adf759e42838aae54a6a8871607f6399aecf)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Se7S-kPkI_J",
        "outputId": "2d216b47-e89d-48a3-a786-89898d0eda81"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['facts', 'labels', 'silver_rationales', 'gold_rationales'],\n",
              "        num_rows: 9000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['facts', 'labels', 'silver_rationales', 'gold_rationales'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['facts', 'labels', 'silver_rationales', 'gold_rationales'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QVz8_s1Ao_R"
      },
      "source": [
        "dataset_train = dataset['train']\n",
        "dataset_validation = dataset['validation']\n",
        "dataset_test = dataset['test']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V10jyibwSmF8",
        "outputId": "885d6042-9163-428a-9d76-85aaf50bda25"
      },
      "source": [
        "!pip install Sentencepiece\n",
        "!pip install transformers\n",
        "import torch"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3iQMfPTSsY6"
      },
      "source": [
        "from transformers import XLMRobertaTokenizer\n",
        "\n",
        "# Download the tokenizer for the XLM-Robert `base` model.\n",
        "xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TceqgMA6aB3R"
      },
      "source": [
        "train_labels = dataset['train']['labels']\n",
        "validation_labels = dataset['validation']['labels']\n",
        "test_labels = dataset['test']['labels']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tM_V70Hj66j"
      },
      "source": [
        "train_facts = dataset['train']['facts']\n",
        "validation_facts = dataset['validation']['facts']\n",
        "test_facts = dataset['test']['facts']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0LufZdMcBl6",
        "outputId": "b12daa94-5856-4774-e6fa-6df11f685535"
      },
      "source": [
        "print(len(train_labels))\n",
        "print(len(validation_labels))\n",
        "print(len(test_labels))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000\n",
            "1000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nouxRiE-ag1h",
        "outputId": "ac5415ca-d8af-4915-f84b-5c9a3b3cd290"
      },
      "source": [
        "print(len(train_facts))\n",
        "print(len(validation_facts))\n",
        "print(len(test_facts))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000\n",
            "1000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66hPUrea-fgX",
        "outputId": "8a8c538b-65d8-4cba-d3c6-b96dcce1b6eb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ewhSVWaf50b"
      },
      "source": [
        "# 保存\n",
        "import numpy as np\n",
        "#labels_a = np.array(list(all_labels_set))\n",
        "#np.save('/content/drive/MyDrive/Data/AIjudge/a.npy',labels_a)   # 保存为.npy格式\n",
        "# 读取\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXNCRjshggCt",
        "outputId": "a6773d34-05a2-437d-eb77-1c3e3cfd910b"
      },
      "source": [
        "a=np.load('/content/drive/MyDrive/Data/AIjudge/a.npy')\n",
        "a=a.tolist()\n",
        "a"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10',\n",
              " '13',\n",
              " 'P1-3',\n",
              " '38',\n",
              " '34',\n",
              " 'P7-5',\n",
              " 'P4-4',\n",
              " 'P12-1',\n",
              " '2',\n",
              " 'P4-2',\n",
              " '5',\n",
              " '6',\n",
              " 'P7-3',\n",
              " 'P7-1',\n",
              " '12',\n",
              " 'P6-3',\n",
              " '8',\n",
              " 'P7-4',\n",
              " '7',\n",
              " '3',\n",
              " '17',\n",
              " '18',\n",
              " '15',\n",
              " 'P1-2',\n",
              " 'P3-1',\n",
              " '14',\n",
              " 'P7-2',\n",
              " 'P1-1',\n",
              " '11',\n",
              " '9',\n",
              " '39',\n",
              " '4',\n",
              " '46']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILxbWse0c5bG",
        "outputId": "fa68fe18-037d-499d-9edb-0bee000edd53"
      },
      "source": [
        "numbers_sorted = sorted(a)\n",
        "numbers_sorted"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['10',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '15',\n",
              " '17',\n",
              " '18',\n",
              " '2',\n",
              " '3',\n",
              " '34',\n",
              " '38',\n",
              " '39',\n",
              " '4',\n",
              " '46',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " 'P1-1',\n",
              " 'P1-2',\n",
              " 'P1-3',\n",
              " 'P12-1',\n",
              " 'P3-1',\n",
              " 'P4-2',\n",
              " 'P4-4',\n",
              " 'P6-3',\n",
              " 'P7-1',\n",
              " 'P7-2',\n",
              " 'P7-3',\n",
              " 'P7-4',\n",
              " 'P7-5']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX6lW6nMiW-w",
        "outputId": "32d2580c-13ed-4d38-f8ad-ae476940160e"
      },
      "source": [
        "len(numbers_sorted)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DwmvMJ7ejsYU",
        "outputId": "9b6c6a37-00f4-417e-bc03-1642ae9a8abc"
      },
      "source": [
        "import pandas as pd\n",
        "# initialise data of lists.\n",
        "train_data = {'Fact':train_facts,'Label':train_labels} \n",
        "# Create DataFrame\n",
        "train_df = pd.DataFrame(train_data) \n",
        "# Print the output.\n",
        "train_df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[11.  At the beginning of the events relevant ...</td>\n",
              "      <td>[13, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[9.  The applicant is the monarch of Liechtens...</td>\n",
              "      <td>[14, P1-1, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[9.  In June 1949 plots of agricultural land o...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[8.  In 1991 Mr Dušan Slobodník, a research wo...</td>\n",
              "      <td>[14, 10, 9]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[9.  The applicant is an Italian citizen, born...</td>\n",
              "      <td>[14, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>[5.  The applicant was born in 1960 and lives ...</td>\n",
              "      <td>[6, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>[5.  The applicant was born in 1946 and is cur...</td>\n",
              "      <td>[4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>[5.  The applicants are Russian nationals who,...</td>\n",
              "      <td>[5, 13, 2, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>[8.  In all cases the applicants brought civil...</td>\n",
              "      <td>[P1-1, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>[4.  The applicant was born in 1971 and lives ...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Fact          Label\n",
              "0     [11.  At the beginning of the events relevant ...        [13, 8]\n",
              "1     [9.  The applicant is the monarch of Liechtens...  [14, P1-1, 6]\n",
              "2     [9.  In June 1949 plots of agricultural land o...            [6]\n",
              "3     [8.  In 1991 Mr Dušan Slobodník, a research wo...    [14, 10, 9]\n",
              "4     [9.  The applicant is an Italian citizen, born...        [14, 6]\n",
              "...                                                 ...            ...\n",
              "8995  [5.  The applicant was born in 1960 and lives ...         [6, 8]\n",
              "8996  [5.  The applicant was born in 1946 and is cur...            [4]\n",
              "8997  [5.  The applicants are Russian nationals who,...  [5, 13, 2, 3]\n",
              "8998  [8.  In all cases the applicants brought civil...      [P1-1, 6]\n",
              "8999  [4.  The applicant was born in 1971 and lives ...            [6]\n",
              "\n",
              "[9000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "e5XySnvXlkpT",
        "outputId": "fbf6727a-6f2a-4e09-825b-54f064c0d921"
      },
      "source": [
        "validation_data = {'Fact':validation_facts,'Label':validation_labels} \n",
        "# Create DataFrame\n",
        "validation_df = pd.DataFrame(validation_data) \n",
        "# Print the output.\n",
        "validation_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[5.  The applicant was born in 1983 and is det...</td>\n",
              "      <td>[8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[5.  The applicant was born in 1982 and is cur...</td>\n",
              "      <td>[3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[5.  The applicant was born in 1955 and lives ...</td>\n",
              "      <td>[3, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[6.  The applicant was born in 1977 and lives ...</td>\n",
              "      <td>[7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[6.  The applicants were born in 1983 and 2007...</td>\n",
              "      <td>[11, 5, 6, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>[5.  The applicant was born in 1965 and lives ...</td>\n",
              "      <td>[11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>[4.  The applicant was born in 1954 and lives ...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>[5.  The applicant company was a Ukrainian joi...</td>\n",
              "      <td>[46, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>[5.  The applicant was born in 1985 and lives ...</td>\n",
              "      <td>[5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>[5.  The applicant was born in 1993 and is det...</td>\n",
              "      <td>[3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact          Label\n",
              "0    [5.  The applicant was born in 1983 and is det...            [8]\n",
              "1    [5.  The applicant was born in 1982 and is cur...            [3]\n",
              "2    [5.  The applicant was born in 1955 and lives ...         [3, 6]\n",
              "3    [6.  The applicant was born in 1977 and lives ...            [7]\n",
              "4    [6.  The applicants were born in 1983 and 2007...  [11, 5, 6, 8]\n",
              "..                                                 ...            ...\n",
              "995  [5.  The applicant was born in 1965 and lives ...           [11]\n",
              "996  [4.  The applicant was born in 1954 and lives ...            [6]\n",
              "997  [5.  The applicant company was a Ukrainian joi...        [46, 6]\n",
              "998  [5.  The applicant was born in 1985 and lives ...            [5]\n",
              "999  [5.  The applicant was born in 1993 and is det...            [3]\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ktvuqTy0lyag",
        "outputId": "f119ebc3-c858-4cfa-91f0-f67fff114585"
      },
      "source": [
        "test_data = {'Fact':test_facts,'Label':test_labels} \n",
        "# Create DataFrame\n",
        "test_df = pd.DataFrame(test_data) \n",
        "# Print the output.\n",
        "test_df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[5.  The applicant is a journalist for DN.no, ...</td>\n",
              "      <td>[10]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[5.  The applicant was born in 1940 and lives ...</td>\n",
              "      <td>[13, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[5.  The applicant was born in 1965 and lives ...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[5.  The applicant was born in 1967 and lives ...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[5.  The applicant was born in 1967 and lives ...</td>\n",
              "      <td>[13, 3, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>[5.  The applicants were born in 1971 and 1976...</td>\n",
              "      <td>[10, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>[5.  The applicant, who was born in 1948, live...</td>\n",
              "      <td>[10, 5, 13, 3, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>[5.  The applicant was born in 1980 and lives ...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>[4.  The applicant was born in 1972 and is det...</td>\n",
              "      <td>[3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>[5.  The applicants were born in 1965, 1977 an...</td>\n",
              "      <td>[13, 8]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact              Label\n",
              "0    [5.  The applicant is a journalist for DN.no, ...               [10]\n",
              "1    [5.  The applicant was born in 1940 and lives ...            [13, 8]\n",
              "2    [5.  The applicant was born in 1965 and lives ...                [6]\n",
              "3    [5.  The applicant was born in 1967 and lives ...                [6]\n",
              "4    [5.  The applicant was born in 1967 and lives ...         [13, 3, 6]\n",
              "..                                                 ...                ...\n",
              "995  [5.  The applicants were born in 1971 and 1976...            [10, 6]\n",
              "996  [5.  The applicant, who was born in 1948, live...  [10, 5, 13, 3, 6]\n",
              "997  [5.  The applicant was born in 1980 and lives ...                [6]\n",
              "998  [4.  The applicant was born in 1972 and is det...                [3]\n",
              "999  [5.  The applicants were born in 1965, 1977 an...            [13, 8]\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRajZ9BEkSXE",
        "outputId": "b08c1274-e7d4-4a89-86f5-ef2d2e327564"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eHIYJgnkTZ-"
      },
      "source": [
        "train_df.to_csv(\"/content/drive/MyDrive/Data/AIjudge/train_df_pandas.csv\")\n",
        "validation_df.to_csv(\"/content/drive/MyDrive/Data/AIjudge/validation_df_pandas.csv\")\n",
        "test_df.to_csv(\"/content/drive/MyDrive/Data/AIjudge/test_df_pandas.csv\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OldqSsasm9p9"
      },
      "source": [
        "n = 0\n",
        "for l in validation_labels:\n",
        "  if n == 0:\n",
        "    validation_labels_set = set(dataset['validation']['labels'][0])\n",
        "  else:\n",
        "    list_of_num = set(dataset['validation']['labels'][n])\n",
        "    validation_labels_set.update(list_of_num)\n",
        "  n += 1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waaTCNzWnMg0",
        "outputId": "c179a2dc-5a62-4888-d296-308aa53dcff5"
      },
      "source": [
        "validation_labels_set"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'10',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '17',\n",
              " '18',\n",
              " '2',\n",
              " '3',\n",
              " '34',\n",
              " '38',\n",
              " '39',\n",
              " '4',\n",
              " '46',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " 'P1-1',\n",
              " 'P1-2',\n",
              " 'P1-3',\n",
              " 'P12-1',\n",
              " 'P4-2',\n",
              " 'P4-4',\n",
              " 'P7-1',\n",
              " 'P7-2',\n",
              " 'P7-4',\n",
              " 'P7-5'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0GakNOIqws-",
        "outputId": "36ecc26f-2ef8-4071-f6dc-5687f0663d6d"
      },
      "source": [
        "# Encode the tags(labels) in a binary format in order to be used for training\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "train_mlb = MultiLabelBinarizer()\n",
        "train_yt = train_mlb.fit_transform(train_labels)\n",
        "validation_mlb = MultiLabelBinarizer()\n",
        "validation_yt = validation_mlb.fit_transform(validation_labels)\n",
        "test_mlb = MultiLabelBinarizer()\n",
        "test_yt = test_mlb.fit_transform(test_labels)\n",
        "print(train_yt.shape)\n",
        "print(validation_yt.shape)\n",
        "print(test_yt.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9000, 33)\n",
            "(1000, 29)\n",
            "(1000, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOEvBENUq56V",
        "outputId": "0309d353-2e56-4b40-df4f-81e2ce0595f4"
      },
      "source": [
        "train_yt"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHVilPn5q8vC",
        "outputId": "05e02c6f-152c-4ef4-e9ec-071d6efb45f9"
      },
      "source": [
        "train_yt[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrc8Hha5qoFf",
        "outputId": "4211b309-ba38-4f77-a87f-3d97d078d832"
      },
      "source": [
        "print(train_yt[0])\n",
        "print(train_mlb.inverse_transform(train_yt[0].reshape(1,-1)))\n",
        "print(train_mlb.classes_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[('13', '8')]\n",
            "['10' '11' '12' '13' '14' '15' '17' '18' '2' '3' '34' '38' '39' '4' '46'\n",
            " '5' '6' '7' '8' '9' 'P1-1' 'P1-2' 'P1-3' 'P12-1' 'P3-1' 'P4-2' 'P4-4'\n",
            " 'P6-3' 'P7-1' 'P7-2' 'P7-3' 'P7-4' 'P7-5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olQsv1SBrHWF",
        "outputId": "2b4f7f47-999a-4285-eb01-fbb61a3091a5"
      },
      "source": [
        "# Getting a sense of how the tags data looks like\n",
        "print(validation_yt[0])\n",
        "print(validation_mlb.inverse_transform(validation_yt[0].reshape(1,-1)))\n",
        "print(validation_mlb.classes_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[('8',)]\n",
            "['10' '11' '12' '13' '14' '17' '18' '2' '3' '34' '38' '39' '4' '46' '5'\n",
            " '6' '7' '8' '9' 'P1-1' 'P1-2' 'P1-3' 'P12-1' 'P4-2' 'P4-4' 'P7-1' 'P7-2'\n",
            " 'P7-4' 'P7-5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAx100P9q-Y-",
        "outputId": "804e2e23-f417-45ff-e0a5-ef751958a6f5"
      },
      "source": [
        "print(test_yt[0])\n",
        "print(test_mlb.inverse_transform(test_yt[0].reshape(1,-1)))\n",
        "print(test_mlb.classes_)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[('10',)]\n",
            "['10' '11' '12' '13' '14' '15' '17' '18' '2' '3' '34' '38' '4' '46' '5'\n",
            " '6' '7' '8' '9' 'P1-1' 'P1-2' 'P1-3' 'P4-2' 'P7-1' 'P7-2' 'P7-3' 'P7-4'\n",
            " 'P7-5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "M98DV1vis3M0",
        "outputId": "55ab4539-f57d-420e-ff8c-62499b8b606e"
      },
      "source": [
        "train_facts[0][0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'11.  At the beginning of the events relevant to the application, K. had a daughter, P., and a son, M., born in 1986 and 1988 respectively. P.’s father is X and M.’s father is V. From March to May 1989 K. was voluntarily hospitalised for about three months, having been diagnosed as suffering from schizophrenia. From August to November 1989 and from December 1989 to March 1990, she was again hospitalised for periods of about three months on account of this illness. In 1991 she was hospitalised for less than a week, diagnosed as suffering from an atypical and undefinable psychosis. It appears that social welfare and health authorities have been in contact with the family since 1989.'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhgQfj1-hN3g",
        "outputId": "e15768b7-a4d2-4490-80a4-573cf5ae3315"
      },
      "source": [
        "import re\n",
        "train_facts_join = []\n",
        "pattern2 = re.compile(r'\\d+.\\s+(.*)')\n",
        "for i in range(len(train_facts)):\n",
        "  train_text0 = train_facts[i][0]\n",
        "  train_s0 = re.search(pattern2, train_text0).group(1)\n",
        "  train_n = 0\n",
        "  train_s = train_s0\n",
        "  for sentence in train_facts[i]:\n",
        "    if train_n > 0:\n",
        "      train_s1 = re.search(pattern2, sentence).group(1)\n",
        "      train_ss = [train_s, train_s1]\n",
        "      train_s = ' '.join(train_ss)\n",
        "    train_n += 1\n",
        "  if ((i % 100) == 0): \n",
        "    print(i)\n",
        "  train_facts_join.append(train_s)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdzJtDHirn9Y",
        "outputId": "da2735f8-1ec9-467c-cf4e-46e403d9598d"
      },
      "source": [
        "validation_facts_join = []\n",
        "pattern2 = re.compile(r'\\d+.\\s+(.*)')\n",
        "for i in range(len(validation_facts)):\n",
        "  validation_text0 = validation_facts[i][0]\n",
        "  validation_s0 = re.search(pattern2, validation_text0).group(1)\n",
        "  validation_n = 0\n",
        "  validation_s = validation_s0\n",
        "  for sentence in validation_facts[i]:\n",
        "    if validation_n > 0:\n",
        "      validation_s1 = re.search(pattern2, sentence).group(1)\n",
        "      validation_ss = [validation_s, validation_s1]\n",
        "      validation_s = ' '.join(validation_ss)\n",
        "    validation_n += 1\n",
        "  if ((i % 100) == 0): \n",
        "    print(i)\n",
        "  validation_facts_join.append(validation_s)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzFeSRh5sB0H",
        "outputId": "0136e887-0d5c-4b56-d0b1-1c9a0b02efbb"
      },
      "source": [
        "test_facts_join = []\n",
        "pattern2 = re.compile(r'\\d+.\\s+(.*)')\n",
        "for i in range(len(test_facts)):\n",
        "  test_text0 = test_facts[i][0]\n",
        "  test_s0 = re.search(pattern2, test_text0).group(1)\n",
        "  test_n = 0\n",
        "  test_s = test_s0\n",
        "  for sentence in test_facts[i]:\n",
        "    if test_n > 0:\n",
        "      test_s1 = re.search(pattern2, sentence).group(1)\n",
        "      test_ss = [test_s, test_s1]\n",
        "      test_s = ' '.join(test_ss)\n",
        "    test_n += 1\n",
        "  if ((i % 100) == 0): \n",
        "    print(i)\n",
        "  test_facts_join.append(test_s)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "DLq0gHWOb-1L",
        "outputId": "a670e16e-607c-4290-aa1e-0b3a65468403"
      },
      "source": [
        "train_facts_join[8900]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The applicant was born in 1958 and is detained in Yuzhno‑Sakhalinsk, Sakhalin Region. The applicant was accused of three counts of aggravated sexual assault and one count of being an accessory to traffic safety violation causing death of two or more persons. During the pre-trial investigation against him he was released on an undertaking not to leave his place of residence. On 4 June 2007 the applicant did not appear at the preliminary hearing scheduled by the Yuzhno-Sakhalinskiy Town Court and the Town Court ordered the applicant’s detention instead of his undertaking not to leave the place of residence. The detention order contained no time-limits. The relevant part of the order read as follows: On 6 June 2007 the applicant appealed against the order. On 8 June 2007 he was arrested and remanded in custody. On 15 June 2007 the applicant’s appeal was sent to the other party. On 19, 20, 21, 22 and 25 June 2007 the applicant complemented his appeal. On 20, 21, 25 and 26 June 2007 the Town Court sent the applicant’s additional pleadings to the other party. On 26 June 2007 the Town Court transmitted the case file to the Regional Court. On 28 June 2007 the Regional Court notified the parties about the date of the hearing scheduled for 18 July 2015. On 2 July 2007 the applicant lodged an application for release which was examined and rejected on 9 July 2007. The Town Court refused to examine the applicant’s arguments concerning the deficiencies of the detention order of 4 June 2007 pending the appeal of the latter. It further rejected as unsubstantiated the applicant’s argument relating to his medical condition. On 3, 10 and 12 July the applicant complemented again his appeal. On 5 and 16 July 2007 the applicant’s complementary appeals were sent to the other party. On 18 July 2007, that is one month and eleven days later, the Sakhalin Regional Court quashed the detention order on appeal and released the applicant. The Regional Court found that the first-instance court failed to comply with the procedure prescribed by Article 247 of the Code of Criminal Procedure providing that a measure of restraint cannot be modified if no such measure had previously been ordered. On 26 July 2007 the applicant was placed under an undertaking not to leave his place of residence.'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTSWlIH8y3XE",
        "outputId": "5c3ae361-fb9c-4216-b101-9daaf52fb769"
      },
      "source": [
        "len(train_facts_join[6497].split())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "315"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "67VDhBK1z0rQ",
        "outputId": "7209d594-10be-4c7b-ed17-1dec77894a17"
      },
      "source": [
        "# initialise data of lists.\n",
        "train_data_join = {'Fact':train_facts_join,\n",
        "    'Label':train_labels}\n",
        " \n",
        "# Create DataFrame\n",
        "train_df_join = pd.DataFrame(train_data_join)\n",
        " \n",
        "# Print the output.\n",
        "train_df_join"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>At the beginning of the events relevant to the...</td>\n",
              "      <td>[13, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant is the monarch of Liechtenstein,...</td>\n",
              "      <td>[14, P1-1, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In June 1949 plots of agricultural land owned ...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In 1991 Mr Dušan Slobodník, a research worker ...</td>\n",
              "      <td>[14, 10, 9]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicant is an Italian citizen, born in 1...</td>\n",
              "      <td>[14, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>The applicant was born in 1960 and lives in th...</td>\n",
              "      <td>[6, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>The applicant was born in 1946 and is currentl...</td>\n",
              "      <td>[4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>The applicants are Russian nationals who, at t...</td>\n",
              "      <td>[5, 13, 2, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>In all cases the applicants brought civil proc...</td>\n",
              "      <td>[P1-1, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>The applicant was born in 1971 and lives in Pé...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Fact          Label\n",
              "0     At the beginning of the events relevant to the...        [13, 8]\n",
              "1     The applicant is the monarch of Liechtenstein,...  [14, P1-1, 6]\n",
              "2     In June 1949 plots of agricultural land owned ...            [6]\n",
              "3     In 1991 Mr Dušan Slobodník, a research worker ...    [14, 10, 9]\n",
              "4     The applicant is an Italian citizen, born in 1...        [14, 6]\n",
              "...                                                 ...            ...\n",
              "8995  The applicant was born in 1960 and lives in th...         [6, 8]\n",
              "8996  The applicant was born in 1946 and is currentl...            [4]\n",
              "8997  The applicants are Russian nationals who, at t...  [5, 13, 2, 3]\n",
              "8998  In all cases the applicants brought civil proc...      [P1-1, 6]\n",
              "8999  The applicant was born in 1971 and lives in Pé...            [6]\n",
              "\n",
              "[9000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3V_Lt7MGufq5",
        "outputId": "3da14b5a-7356-41a6-99a0-04b791ac9d07"
      },
      "source": [
        "# initialise data of lists.\n",
        "validation_data_join = {'Fact':validation_facts_join, 'Label':validation_labels} \n",
        "# Create DataFrame\n",
        "validation_df_join = pd.DataFrame(validation_data_join) \n",
        "# Print the output.\n",
        "validation_df_join"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The applicant was born in 1983 and is detained...</td>\n",
              "      <td>[8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant was born in 1982 and is currentl...</td>\n",
              "      <td>[3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The applicant was born in 1955 and lives in Na...</td>\n",
              "      <td>[3, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The applicant was born in 1977 and lives in Lu...</td>\n",
              "      <td>[7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicants were born in 1983 and 2007 resp...</td>\n",
              "      <td>[11, 5, 6, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The applicant was born in 1965 and lives in Bu...</td>\n",
              "      <td>[11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The applicant was born in 1954 and lives in Do...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The applicant company was a Ukrainian joint-st...</td>\n",
              "      <td>[46, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The applicant was born in 1985 and lives in Wa...</td>\n",
              "      <td>[5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>The applicant was born in 1993 and is detained...</td>\n",
              "      <td>[3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact          Label\n",
              "0    The applicant was born in 1983 and is detained...            [8]\n",
              "1    The applicant was born in 1982 and is currentl...            [3]\n",
              "2    The applicant was born in 1955 and lives in Na...         [3, 6]\n",
              "3    The applicant was born in 1977 and lives in Lu...            [7]\n",
              "4    The applicants were born in 1983 and 2007 resp...  [11, 5, 6, 8]\n",
              "..                                                 ...            ...\n",
              "995  The applicant was born in 1965 and lives in Bu...           [11]\n",
              "996  The applicant was born in 1954 and lives in Do...            [6]\n",
              "997  The applicant company was a Ukrainian joint-st...        [46, 6]\n",
              "998  The applicant was born in 1985 and lives in Wa...            [5]\n",
              "999  The applicant was born in 1993 and is detained...            [3]\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gaX2OhEKuq8k",
        "outputId": "da716d4c-0a4f-49d1-bd65-d7af4a787587"
      },
      "source": [
        "# initialise data of lists.\n",
        "test_data_join = {'Fact':test_facts_join, 'Label':test_labels} \n",
        "# Create DataFrame\n",
        "test_df_join = pd.DataFrame(test_data_join) \n",
        "# Print the output.\n",
        "test_df_join"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The applicant is a journalist for DN.no, a Nor...</td>\n",
              "      <td>[10]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant was born in 1940 and lives in Od...</td>\n",
              "      <td>[13, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The applicant was born in 1965 and lives in Sm...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The applicant was born in 1967 and lives in Ky...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicant was born in 1967 and lives in St...</td>\n",
              "      <td>[13, 3, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The applicants were born in 1971 and 1976 and ...</td>\n",
              "      <td>[10, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The applicant, who was born in 1948, lives in ...</td>\n",
              "      <td>[10, 5, 13, 3, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The applicant was born in 1980 and lives in Gr...</td>\n",
              "      <td>[6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The applicant was born in 1972 and is detained...</td>\n",
              "      <td>[3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>The applicants were born in 1965, 1977 and 197...</td>\n",
              "      <td>[13, 8]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact              Label\n",
              "0    The applicant is a journalist for DN.no, a Nor...               [10]\n",
              "1    The applicant was born in 1940 and lives in Od...            [13, 8]\n",
              "2    The applicant was born in 1965 and lives in Sm...                [6]\n",
              "3    The applicant was born in 1967 and lives in Ky...                [6]\n",
              "4    The applicant was born in 1967 and lives in St...         [13, 3, 6]\n",
              "..                                                 ...                ...\n",
              "995  The applicants were born in 1971 and 1976 and ...            [10, 6]\n",
              "996  The applicant, who was born in 1948, lives in ...  [10, 5, 13, 3, 6]\n",
              "997  The applicant was born in 1980 and lives in Gr...                [6]\n",
              "998  The applicant was born in 1972 and is detained...                [3]\n",
              "999  The applicants were born in 1965, 1977 and 197...            [13, 8]\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "35ch1keHamx-",
        "outputId": "5af97bf9-cc29-46f7-8d49-e4cb27d7e6c9"
      },
      "source": [
        "import pandas as pd\n",
        "train_df_labels_onehot = pd.DataFrame(train_yt, columns = train_mlb.classes_.tolist())\n",
        "train_df_labels_onehot"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>34</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>4</th>\n",
              "      <th>46</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>P1-1</th>\n",
              "      <th>P1-2</th>\n",
              "      <th>P1-3</th>\n",
              "      <th>P12-1</th>\n",
              "      <th>P3-1</th>\n",
              "      <th>P4-2</th>\n",
              "      <th>P4-4</th>\n",
              "      <th>P6-3</th>\n",
              "      <th>P7-1</th>\n",
              "      <th>P7-2</th>\n",
              "      <th>P7-3</th>\n",
              "      <th>P7-4</th>\n",
              "      <th>P7-5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      10  11  12  13  14  15  17  ...  P4-4  P6-3  P7-1  P7-2  P7-3  P7-4  P7-5\n",
              "0      0   0   0   1   0   0   0  ...     0     0     0     0     0     0     0\n",
              "1      0   0   0   0   1   0   0  ...     0     0     0     0     0     0     0\n",
              "2      0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "3      1   0   0   0   1   0   0  ...     0     0     0     0     0     0     0\n",
              "4      0   0   0   0   1   0   0  ...     0     0     0     0     0     0     0\n",
              "...   ..  ..  ..  ..  ..  ..  ..  ...   ...   ...   ...   ...   ...   ...   ...\n",
              "8995   0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "8996   0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "8997   0   0   0   1   0   0   0  ...     0     0     0     0     0     0     0\n",
              "8998   0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "8999   0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "\n",
              "[9000 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jC2km38lb0E8",
        "outputId": "684a297e-4fb0-4ea4-a01c-f0b503051c58"
      },
      "source": [
        "# initialise data of lists.\n",
        "train_data_fact = {'Fact':train_facts_join}\n",
        "# Create DataFrame\n",
        "train_df_fact = pd.DataFrame(train_data_fact)\n",
        "# Print the output.\n",
        "train_df_fact"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>At the beginning of the events relevant to the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant is the monarch of Liechtenstein,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In June 1949 plots of agricultural land owned ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In 1991 Mr Dušan Slobodník, a research worker ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicant is an Italian citizen, born in 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>The applicant was born in 1960 and lives in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>The applicant was born in 1946 and is currentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>The applicants are Russian nationals who, at t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>In all cases the applicants brought civil proc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>The applicant was born in 1971 and lives in Pé...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Fact\n",
              "0     At the beginning of the events relevant to the...\n",
              "1     The applicant is the monarch of Liechtenstein,...\n",
              "2     In June 1949 plots of agricultural land owned ...\n",
              "3     In 1991 Mr Dušan Slobodník, a research worker ...\n",
              "4     The applicant is an Italian citizen, born in 1...\n",
              "...                                                 ...\n",
              "8995  The applicant was born in 1960 and lives in th...\n",
              "8996  The applicant was born in 1946 and is currentl...\n",
              "8997  The applicants are Russian nationals who, at t...\n",
              "8998  In all cases the applicants brought civil proc...\n",
              "8999  The applicant was born in 1971 and lives in Pé...\n",
              "\n",
              "[9000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ToP3xLRDb9_9",
        "outputId": "b65bf161-d136-4256-f75b-1145e71a03b3"
      },
      "source": [
        "train_merged = pd.concat([train_df_fact, train_df_labels_onehot],axis=1)\n",
        "train_merged"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>34</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>4</th>\n",
              "      <th>46</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>P1-1</th>\n",
              "      <th>P1-2</th>\n",
              "      <th>P1-3</th>\n",
              "      <th>P12-1</th>\n",
              "      <th>P3-1</th>\n",
              "      <th>P4-2</th>\n",
              "      <th>P4-4</th>\n",
              "      <th>P6-3</th>\n",
              "      <th>P7-1</th>\n",
              "      <th>P7-2</th>\n",
              "      <th>P7-3</th>\n",
              "      <th>P7-4</th>\n",
              "      <th>P7-5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>At the beginning of the events relevant to the...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant is the monarch of Liechtenstein,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In June 1949 plots of agricultural land owned ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In 1991 Mr Dušan Slobodník, a research worker ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicant is an Italian citizen, born in 1...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>The applicant was born in 1960 and lives in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>The applicant was born in 1946 and is currentl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>The applicants are Russian nationals who, at t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>In all cases the applicants brought civil proc...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>The applicant was born in 1971 and lives in Pé...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Fact  10  ...  P7-4  P7-5\n",
              "0     At the beginning of the events relevant to the...   0  ...     0     0\n",
              "1     The applicant is the monarch of Liechtenstein,...   0  ...     0     0\n",
              "2     In June 1949 plots of agricultural land owned ...   0  ...     0     0\n",
              "3     In 1991 Mr Dušan Slobodník, a research worker ...   1  ...     0     0\n",
              "4     The applicant is an Italian citizen, born in 1...   0  ...     0     0\n",
              "...                                                 ...  ..  ...   ...   ...\n",
              "8995  The applicant was born in 1960 and lives in th...   0  ...     0     0\n",
              "8996  The applicant was born in 1946 and is currentl...   0  ...     0     0\n",
              "8997  The applicants are Russian nationals who, at t...   0  ...     0     0\n",
              "8998  In all cases the applicants brought civil proc...   0  ...     0     0\n",
              "8999  The applicant was born in 1971 and lives in Pé...   0  ...     0     0\n",
              "\n",
              "[9000 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "3btH46Tu3MrF",
        "outputId": "73b7ae23-a827-439d-af08-8b525401b8e0"
      },
      "source": [
        "validation_df_labels_onehot = pd.DataFrame(validation_yt, columns = validation_mlb.classes_.tolist())\n",
        "validation_df_labels_onehot"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>34</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>4</th>\n",
              "      <th>46</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>P1-1</th>\n",
              "      <th>P1-2</th>\n",
              "      <th>P1-3</th>\n",
              "      <th>P12-1</th>\n",
              "      <th>P4-2</th>\n",
              "      <th>P4-4</th>\n",
              "      <th>P7-1</th>\n",
              "      <th>P7-2</th>\n",
              "      <th>P7-4</th>\n",
              "      <th>P7-5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     10  11  12  13  14  17  18  ...  P12-1  P4-2  P4-4  P7-1  P7-2  P7-4  P7-5\n",
              "0     0   0   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "1     0   0   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "2     0   0   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "3     0   0   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "4     0   1   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "..   ..  ..  ..  ..  ..  ..  ..  ...    ...   ...   ...   ...   ...   ...   ...\n",
              "995   0   1   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "996   0   0   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "997   0   0   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "998   0   0   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "999   0   0   0   0   0   0   0  ...      0     0     0     0     0     0     0\n",
              "\n",
              "[1000 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "ENtgSf43LLkO",
        "outputId": "24145531-3ad7-41c6-a529-41427094e979"
      },
      "source": [
        "test_df_labels_onehot = pd.DataFrame(test_yt, columns = test_mlb.classes_.tolist())\n",
        "test_df_labels_onehot"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>34</th>\n",
              "      <th>38</th>\n",
              "      <th>4</th>\n",
              "      <th>46</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>P1-1</th>\n",
              "      <th>P1-2</th>\n",
              "      <th>P1-3</th>\n",
              "      <th>P4-2</th>\n",
              "      <th>P7-1</th>\n",
              "      <th>P7-2</th>\n",
              "      <th>P7-3</th>\n",
              "      <th>P7-4</th>\n",
              "      <th>P7-5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     10  11  12  13  14  15  17  ...  P1-3  P4-2  P7-1  P7-2  P7-3  P7-4  P7-5\n",
              "0     1   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "1     0   0   0   1   0   0   0  ...     0     0     0     0     0     0     0\n",
              "2     0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "3     0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "4     0   0   0   1   0   0   0  ...     0     0     0     0     0     0     0\n",
              "..   ..  ..  ..  ..  ..  ..  ..  ...   ...   ...   ...   ...   ...   ...   ...\n",
              "995   1   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "996   1   0   0   1   0   0   0  ...     0     0     0     0     0     0     0\n",
              "997   0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "998   0   0   0   0   0   0   0  ...     0     0     0     0     0     0     0\n",
              "999   0   0   0   1   0   0   0  ...     0     0     0     0     0     0     0\n",
              "\n",
              "[1000 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX45WdVo3bMv",
        "outputId": "b044657c-6ede-4bfb-ffc2-30ddfcae5c13"
      },
      "source": [
        "validation_df_labels_onehot.columns"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['10', '11', '12', '13', '14', '17', '18', '2', '3', '34', '38', '39',\n",
              "       '4', '46', '5', '6', '7', '8', '9', 'P1-1', 'P1-2', 'P1-3', 'P12-1',\n",
              "       'P4-2', 'P4-4', 'P7-1', 'P7-2', 'P7-4', 'P7-5'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pma3leKy3eXX",
        "outputId": "5b2759c4-96ba-4604-accf-8d1bc3984dea"
      },
      "source": [
        "train_df_labels_onehot.columns"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['10', '11', '12', '13', '14', '15', '17', '18', '2', '3', '34', '38',\n",
              "       '39', '4', '46', '5', '6', '7', '8', '9', 'P1-1', 'P1-2', 'P1-3',\n",
              "       'P12-1', 'P3-1', 'P4-2', 'P4-4', 'P6-3', 'P7-1', 'P7-2', 'P7-3', 'P7-4',\n",
              "       'P7-5'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTm8Oxu336sf"
      },
      "source": [
        "x = set(train_df_labels_onehot.columns)\n",
        "y = set(validation_df_labels_onehot.columns)\n",
        "z = set(test_df_labels_onehot.columns)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyJilydC3kXD",
        "outputId": "3ca28266-3b42-49a5-b01f-de22cba62dfc"
      },
      "source": [
        "diff = sorted(list(x.symmetric_difference(y)))\n",
        "diff"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['15', 'P3-1', 'P6-3', 'P7-3']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWfkN6SNLR5p",
        "outputId": "3914600d-dcc0-4764-81f0-703342441379"
      },
      "source": [
        "diff_tr_te = sorted(list(x.symmetric_difference(z)))\n",
        "diff_tr_te"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['39', 'P12-1', 'P3-1', 'P4-4', 'P6-3']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpHuolMSLefM",
        "outputId": "948c1876-03a2-4155-81f6-6787f62ff13a"
      },
      "source": [
        "idx_tr_te = []\n",
        "xlist = list(sorted(x))\n",
        "for i in range(len(diff_tr_te)):\n",
        "  p_tr_te=xlist.index(diff_tr_te[i])\n",
        "  idx_tr_te.append(p_tr_te)\n",
        "idx_tr_te"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12, 23, 24, 26, 27]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlKbDO865w63"
      },
      "source": [
        "idx = []\n",
        "xlist = list(sorted(x))\n",
        "for i in range(len(diff)):\n",
        "  p=xlist.index(diff[i])\n",
        "  idx.append(p)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHmxW1xY5uIE",
        "outputId": "3408f81c-9a01-47a0-8ab6-389588f739cb"
      },
      "source": [
        "idx"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 24, 27, 30]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0sk89t16qNm"
      },
      "source": [
        "validation_df_labels_onehot.insert(5, '15', np.zeros(1000, dtype = \"int\"))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq1ngye77FLJ"
      },
      "source": [
        "validation_df_labels_onehot.insert(idx[1], diff[1], np.zeros(1000, dtype = \"int\"))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfqXZtmo7gKR"
      },
      "source": [
        "validation_df_labels_onehot.insert(idx[2], diff[2], np.zeros(1000, dtype = \"int\"))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZEYSIsb7l9f"
      },
      "source": [
        "validation_df_labels_onehot.insert(idx[3], diff[3], np.zeros(1000, dtype = \"int\"))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSTYESg47nDv",
        "outputId": "8fe4b583-6d96-4aa7-df84-ef8b9edc5cb0"
      },
      "source": [
        "validation_df_labels_onehot.columns"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['10', '11', '12', '13', '14', '15', '17', '18', '2', '3', '34', '38',\n",
              "       '39', '4', '46', '5', '6', '7', '8', '9', 'P1-1', 'P1-2', 'P1-3',\n",
              "       'P12-1', 'P3-1', 'P4-2', 'P4-4', 'P6-3', 'P7-1', 'P7-2', 'P7-3', 'P7-4',\n",
              "       'P7-5'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "598D0Wob7q0M",
        "outputId": "d21e6c3e-eef9-4266-b46e-b24148497eb1"
      },
      "source": [
        "validation_df_labels_onehot.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yuIYDezU4dwh",
        "outputId": "66afdf44-b995-4365-857b-3909626d11d2"
      },
      "source": [
        "# initialise data of lists.\n",
        "validation_data_fact = {'Fact':validation_facts_join}\n",
        "# Create DataFrame\n",
        "validation_df_fact = pd.DataFrame(validation_data_fact)\n",
        "# Print the output.\n",
        "validation_df_fact"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The applicant was born in 1983 and is detained...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant was born in 1982 and is currentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The applicant was born in 1955 and lives in Na...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The applicant was born in 1977 and lives in Lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicants were born in 1983 and 2007 resp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The applicant was born in 1965 and lives in Bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The applicant was born in 1954 and lives in Do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The applicant company was a Ukrainian joint-st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The applicant was born in 1985 and lives in Wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>The applicant was born in 1993 and is detained...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact\n",
              "0    The applicant was born in 1983 and is detained...\n",
              "1    The applicant was born in 1982 and is currentl...\n",
              "2    The applicant was born in 1955 and lives in Na...\n",
              "3    The applicant was born in 1977 and lives in Lu...\n",
              "4    The applicants were born in 1983 and 2007 resp...\n",
              "..                                                 ...\n",
              "995  The applicant was born in 1965 and lives in Bu...\n",
              "996  The applicant was born in 1954 and lives in Do...\n",
              "997  The applicant company was a Ukrainian joint-st...\n",
              "998  The applicant was born in 1985 and lives in Wa...\n",
              "999  The applicant was born in 1993 and is detained...\n",
              "\n",
              "[1000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eGLfeYQJ79tk",
        "outputId": "5931e95b-f693-49c0-d3bf-6a1229355d4a"
      },
      "source": [
        "validation_merged = pd.concat([validation_df_fact, validation_df_labels_onehot],axis=1)\n",
        "validation_merged"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>34</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>4</th>\n",
              "      <th>46</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>P1-1</th>\n",
              "      <th>P1-2</th>\n",
              "      <th>P1-3</th>\n",
              "      <th>P12-1</th>\n",
              "      <th>P3-1</th>\n",
              "      <th>P4-2</th>\n",
              "      <th>P4-4</th>\n",
              "      <th>P6-3</th>\n",
              "      <th>P7-1</th>\n",
              "      <th>P7-2</th>\n",
              "      <th>P7-3</th>\n",
              "      <th>P7-4</th>\n",
              "      <th>P7-5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The applicant was born in 1983 and is detained...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant was born in 1982 and is currentl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The applicant was born in 1955 and lives in Na...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The applicant was born in 1977 and lives in Lu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicants were born in 1983 and 2007 resp...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The applicant was born in 1965 and lives in Bu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The applicant was born in 1954 and lives in Do...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The applicant company was a Ukrainian joint-st...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The applicant was born in 1985 and lives in Wa...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>The applicant was born in 1993 and is detained...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact  10  ...  P7-4  P7-5\n",
              "0    The applicant was born in 1983 and is detained...   0  ...     0     0\n",
              "1    The applicant was born in 1982 and is currentl...   0  ...     0     0\n",
              "2    The applicant was born in 1955 and lives in Na...   0  ...     0     0\n",
              "3    The applicant was born in 1977 and lives in Lu...   0  ...     0     0\n",
              "4    The applicants were born in 1983 and 2007 resp...   0  ...     0     0\n",
              "..                                                 ...  ..  ...   ...   ...\n",
              "995  The applicant was born in 1965 and lives in Bu...   0  ...     0     0\n",
              "996  The applicant was born in 1954 and lives in Do...   0  ...     0     0\n",
              "997  The applicant company was a Ukrainian joint-st...   0  ...     0     0\n",
              "998  The applicant was born in 1985 and lives in Wa...   0  ...     0     0\n",
              "999  The applicant was born in 1993 and is detained...   0  ...     0     0\n",
              "\n",
              "[1000 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lTY6VJ_R0wrl",
        "outputId": "64914d3a-6985-454c-d428-ae20bdfb0c1a"
      },
      "source": [
        "# initialise data of lists.\n",
        "test_data_fact = {'Fact':test_facts_join}\n",
        "# Create DataFrame\n",
        "test_df_fact = pd.DataFrame(test_data_fact)\n",
        "# Print the output.\n",
        "test_df_fact"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The applicant is a journalist for DN.no, a Nor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant was born in 1940 and lives in Od...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The applicant was born in 1965 and lives in Sm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The applicant was born in 1967 and lives in Ky...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicant was born in 1967 and lives in St...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The applicants were born in 1971 and 1976 and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The applicant, who was born in 1948, lives in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The applicant was born in 1980 and lives in Gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The applicant was born in 1972 and is detained...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>The applicants were born in 1965, 1977 and 197...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact\n",
              "0    The applicant is a journalist for DN.no, a Nor...\n",
              "1    The applicant was born in 1940 and lives in Od...\n",
              "2    The applicant was born in 1965 and lives in Sm...\n",
              "3    The applicant was born in 1967 and lives in Ky...\n",
              "4    The applicant was born in 1967 and lives in St...\n",
              "..                                                 ...\n",
              "995  The applicants were born in 1971 and 1976 and ...\n",
              "996  The applicant, who was born in 1948, lives in ...\n",
              "997  The applicant was born in 1980 and lives in Gr...\n",
              "998  The applicant was born in 1972 and is detained...\n",
              "999  The applicants were born in 1965, 1977 and 197...\n",
              "\n",
              "[1000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mrOD3CS_0ewU",
        "outputId": "595a2ac2-c4fc-4845-b93f-11f4480f79ce"
      },
      "source": [
        "test_merged = pd.concat([test_df_fact, test_df_labels_onehot], axis=1)\n",
        "test_merged"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>34</th>\n",
              "      <th>38</th>\n",
              "      <th>4</th>\n",
              "      <th>46</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>P1-1</th>\n",
              "      <th>P1-2</th>\n",
              "      <th>P1-3</th>\n",
              "      <th>P4-2</th>\n",
              "      <th>P7-1</th>\n",
              "      <th>P7-2</th>\n",
              "      <th>P7-3</th>\n",
              "      <th>P7-4</th>\n",
              "      <th>P7-5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The applicant is a journalist for DN.no, a Nor...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant was born in 1940 and lives in Od...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The applicant was born in 1965 and lives in Sm...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The applicant was born in 1967 and lives in Ky...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicant was born in 1967 and lives in St...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The applicants were born in 1971 and 1976 and ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The applicant, who was born in 1948, lives in ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The applicant was born in 1980 and lives in Gr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The applicant was born in 1972 and is detained...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>The applicants were born in 1965, 1977 and 197...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact  10  ...  P7-4  P7-5\n",
              "0    The applicant is a journalist for DN.no, a Nor...   1  ...     0     0\n",
              "1    The applicant was born in 1940 and lives in Od...   0  ...     0     0\n",
              "2    The applicant was born in 1965 and lives in Sm...   0  ...     0     0\n",
              "3    The applicant was born in 1967 and lives in Ky...   0  ...     0     0\n",
              "4    The applicant was born in 1967 and lives in St...   0  ...     0     0\n",
              "..                                                 ...  ..  ...   ...   ...\n",
              "995  The applicants were born in 1971 and 1976 and ...   1  ...     0     0\n",
              "996  The applicant, who was born in 1948, lives in ...   1  ...     0     0\n",
              "997  The applicant was born in 1980 and lives in Gr...   0  ...     0     0\n",
              "998  The applicant was born in 1972 and is detained...   0  ...     0     0\n",
              "999  The applicants were born in 1965, 1977 and 197...   0  ...     0     0\n",
              "\n",
              "[1000 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ9zmA758FD4"
      },
      "source": [
        "train_merged.to_csv(\"/content/drive/MyDrive/Data/AIjudge/train_merged.csv\")\n",
        "validation_merged.to_csv(\"/content/drive/MyDrive/Data/AIjudge/validation_merged.csv\")\n",
        "test_merged.to_csv(\"/content/drive/MyDrive/Data/AIjudge/test_merged.csv\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWoQbHSXXfUY"
      },
      "source": [
        "# These are the 33 possible labels.\n",
        "train_label_cols = train_mlb.classes_.tolist()\n",
        "# Select just the labels (not the text), and for every row, check whether any\n",
        "# of the labels are \"1\".\n",
        "train_has_labels = train_merged[train_label_cols].any(axis=1)\n",
        "# Add a new column indicating which samples have no violated articles.\n",
        "train_merged['unviolated'] = 1 - train_has_labels\n",
        "# Add the 'unviolated' column to our list of label names.\n",
        "train_label_cols.append('unviolated')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zo7O7SaspMZ",
        "outputId": "23f2f33e-1e0c-42d9-e56e-f4fd3d01e5b5"
      },
      "source": [
        "train_merged['unviolated']"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "8995    0\n",
              "8996    0\n",
              "8997    0\n",
              "8998    0\n",
              "8999    0\n",
              "Name: unviolated, Length: 9000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc-_UMMMdcOj",
        "outputId": "80b29aa7-85ce-4a9d-9ec6-92beb6e250c1"
      },
      "source": [
        "# Tally up each label separately.\n",
        "train_label_counts = train_merged[train_label_cols].sum(axis=0)\n",
        "print(train_label_counts)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10             441\n",
            "11             162\n",
            "12              16\n",
            "13            1665\n",
            "14             444\n",
            "15               6\n",
            "17              31\n",
            "18              42\n",
            "2              623\n",
            "3             1740\n",
            "34             547\n",
            "38             119\n",
            "39             159\n",
            "4               26\n",
            "46             187\n",
            "5             1623\n",
            "6             5437\n",
            "7               72\n",
            "8             1056\n",
            "9               81\n",
            "P1-1          1558\n",
            "P1-2            15\n",
            "P1-3            61\n",
            "P12-1            5\n",
            "P3-1             1\n",
            "P4-2            48\n",
            "P4-4             7\n",
            "P6-3             1\n",
            "P7-1             7\n",
            "P7-2            17\n",
            "P7-3             1\n",
            "P7-4            29\n",
            "P7-5             2\n",
            "unviolated      45\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99HSgRyVzgpA"
      },
      "source": [
        "# These are the 33 possible labels.\n",
        "train_label_cols = train_mlb.classes_.tolist()\n",
        "# Select just the labels (not the text), and for every row, check whether any\n",
        "# of the labels are \"1\".\n",
        "train_has_labels = train_merged[train_label_cols].any(axis=1)\n",
        "# Add a new column indicating which samples have no violated articles.\n",
        "train_merged['unviolated'] = 1 - train_has_labels\n",
        "# Add the 'unviolated' column to our list of label names.\n",
        "train_label_cols.append('unviolated')"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBHD6btRxA0W"
      },
      "source": [
        "label_bi = train_merged['unviolated']"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rGajbYUWxdDw",
        "outputId": "37ff6e90-2d96-4687-8974-2ee8a5f0ec46"
      },
      "source": [
        "train_bi = pd.concat([train_df_fact, label_bi],axis=1)\n",
        "train_bi"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>unviolated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>At the beginning of the events relevant to the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant is the monarch of Liechtenstein,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In June 1949 plots of agricultural land owned ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In 1991 Mr Dušan Slobodník, a research worker ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicant is an Italian citizen, born in 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>The applicant was born in 1960 and lives in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>The applicant was born in 1946 and is currentl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>The applicants are Russian nationals who, at t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>In all cases the applicants brought civil proc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>The applicant was born in 1971 and lives in Pé...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Fact  unviolated\n",
              "0     At the beginning of the events relevant to the...           0\n",
              "1     The applicant is the monarch of Liechtenstein,...           0\n",
              "2     In June 1949 plots of agricultural land owned ...           0\n",
              "3     In 1991 Mr Dušan Slobodník, a research worker ...           0\n",
              "4     The applicant is an Italian citizen, born in 1...           0\n",
              "...                                                 ...         ...\n",
              "8995  The applicant was born in 1960 and lives in th...           0\n",
              "8996  The applicant was born in 1946 and is currentl...           0\n",
              "8997  The applicants are Russian nationals who, at t...           0\n",
              "8998  In all cases the applicants brought civil proc...           0\n",
              "8999  The applicant was born in 1971 and lives in Pé...           0\n",
              "\n",
              "[9000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt5O7YfzdnXA",
        "outputId": "44c7ca26-7a01-485f-81ad-8a53c38f6e76"
      },
      "source": [
        "print('{:.1%} of the instances did not violate any articles.'.format(train_label_counts['unviolated'] / len(train_merged)))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5% of the instances did not violate any articles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QiVD-THkx2mC",
        "outputId": "41908114-62cb-4d56-8e89-1ded1c2dc861"
      },
      "source": [
        "# These are the 33 possible labels.\n",
        "validation_label_cols = validation_mlb.classes_.tolist()\n",
        "# Select just the labels (not the text), and for every row, check whether any\n",
        "# of the labels are \"1\".\n",
        "validation_has_labels = validation_merged[validation_label_cols].any(axis=1)\n",
        "# Add a new column indicating which samples have no violated articles.\n",
        "validation_merged['unviolated'] = 1 - validation_has_labels\n",
        "# Add the 'unviolated' column to our list of label names.\n",
        "validation_label_cols.append('unviolated')\n",
        "validation_label_bi = validation_merged['unviolated']\n",
        "validation_bi = pd.concat([validation_df_fact, validation_label_bi],axis=1)\n",
        "validation_bi"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>unviolated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The applicant was born in 1983 and is detained...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant was born in 1982 and is currentl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The applicant was born in 1955 and lives in Na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The applicant was born in 1977 and lives in Lu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicants were born in 1983 and 2007 resp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The applicant was born in 1965 and lives in Bu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The applicant was born in 1954 and lives in Do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The applicant company was a Ukrainian joint-st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The applicant was born in 1985 and lives in Wa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>The applicant was born in 1993 and is detained...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact  unviolated\n",
              "0    The applicant was born in 1983 and is detained...           0\n",
              "1    The applicant was born in 1982 and is currentl...           0\n",
              "2    The applicant was born in 1955 and lives in Na...           0\n",
              "3    The applicant was born in 1977 and lives in Lu...           0\n",
              "4    The applicants were born in 1983 and 2007 resp...           0\n",
              "..                                                 ...         ...\n",
              "995  The applicant was born in 1965 and lives in Bu...           0\n",
              "996  The applicant was born in 1954 and lives in Do...           0\n",
              "997  The applicant company was a Ukrainian joint-st...           0\n",
              "998  The applicant was born in 1985 and lives in Wa...           0\n",
              "999  The applicant was born in 1993 and is detained...           0\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr3lQoLAyone",
        "outputId": "00f0f7d9-be30-4b2a-c4c4-dc73815b08f9"
      },
      "source": [
        "# Add the 'unviolated' column to our list of label names.\n",
        "#validation_label_cols.append('unviolated')\n",
        "val_label_counts = validation_merged[validation_label_cols].sum(axis=0)\n",
        "print('{:.1%} of the instances did not violate any articles.'.format(val_label_counts['unviolated'] / len(validation_merged)))\n",
        "val_label_counts"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1% of the instances did not violate any articles.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10             64\n",
              "11             39\n",
              "12              2\n",
              "13            112\n",
              "14             34\n",
              "17              1\n",
              "18              5\n",
              "2              75\n",
              "3             236\n",
              "34             65\n",
              "38              2\n",
              "39              1\n",
              "4               5\n",
              "46             19\n",
              "5             219\n",
              "6             394\n",
              "7              10\n",
              "8             153\n",
              "9               9\n",
              "P1-1          168\n",
              "P1-2            1\n",
              "P1-3           11\n",
              "P12-1           1\n",
              "P4-2            9\n",
              "P4-4            3\n",
              "P7-1            3\n",
              "P7-2            1\n",
              "P7-4            7\n",
              "P7-5            1\n",
              "unviolated      1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l7SRKvyzuaA"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b1nDYBb8zkMc",
        "outputId": "84db25f8-fbb0-4662-901f-c4f4d2090272"
      },
      "source": [
        "# These are the 33 possible labels.\n",
        "test_label_cols = test_mlb.classes_.tolist()\n",
        "# Select just the labels (not the text), and for every row, check whether any\n",
        "# of the labels are \"1\".\n",
        "test_has_labels = test_merged[test_label_cols].any(axis=1)\n",
        "# Add a new column indicating which samples have no violated articles.\n",
        "test_merged['unviolated'] = 1 - test_has_labels\n",
        "# Add the 'unviolated' column to our list of label names.\n",
        "test_label_cols.append('unviolated')\n",
        "test_label_bi = test_merged['unviolated']\n",
        "\n",
        "test_bi = pd.concat([test_df_fact, test_label_bi],axis=1)\n",
        "test_bi"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fact</th>\n",
              "      <th>unviolated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The applicant is a journalist for DN.no, a Nor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The applicant was born in 1940 and lives in Od...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The applicant was born in 1965 and lives in Sm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The applicant was born in 1967 and lives in Ky...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The applicant was born in 1967 and lives in St...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The applicants were born in 1971 and 1976 and ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The applicant, who was born in 1948, lives in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>The applicant was born in 1980 and lives in Gr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The applicant was born in 1972 and is detained...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>The applicants were born in 1965, 1977 and 197...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Fact  unviolated\n",
              "0    The applicant is a journalist for DN.no, a Nor...           0\n",
              "1    The applicant was born in 1940 and lives in Od...           0\n",
              "2    The applicant was born in 1965 and lives in Sm...           0\n",
              "3    The applicant was born in 1967 and lives in Ky...           0\n",
              "4    The applicant was born in 1967 and lives in St...           0\n",
              "..                                                 ...         ...\n",
              "995  The applicants were born in 1971 and 1976 and ...           0\n",
              "996  The applicant, who was born in 1948, lives in ...           0\n",
              "997  The applicant was born in 1980 and lives in Gr...           0\n",
              "998  The applicant was born in 1972 and is detained...           0\n",
              "999  The applicants were born in 1965, 1977 and 197...           0\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_CrkcjEwd0I"
      },
      "source": [
        "train_bi.to_csv(\"/content/drive/MyDrive/Data/AIjudge/train_bi.csv\")\n",
        "validation_bi.to_csv(\"/content/drive/MyDrive/Data/AIjudge/validation_bi.csv\")\n",
        "test_bi.to_csv(\"/content/drive/MyDrive/Data/AIjudge/test_bi.csv\")"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqBVDVS8gquF",
        "outputId": "78ddb6c9-a377-4385-c3ba-e5affeef59fa"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_lengths_en = []\n",
        "\n",
        "train_labels_en = []\n",
        "\n",
        "print('Tokenizing all examples to check sequence lengths...')\n",
        "\n",
        "train_labels = train_df_join.Label.to_numpy()\n",
        "\n",
        "# Iterate through the dataset...\n",
        "for i, sen in enumerate(train_df_join.Fact):\n",
        "    \n",
        "    # Report progress.\n",
        "    if ((len(train_lengths_en) % 3000) == 0):\n",
        "        print('  Tokenized {:,} samples.'.format(len(train_lengths_en)))\n",
        "    \n",
        "    # `tokenizer.encode` will tokenize the sentence, map the tokens to ids, \n",
        "    # and add the required special tokens.:\n",
        "    train_encoded = xlmr_tokenizer.encode(sen, add_special_tokens = True)\n",
        "\n",
        "    # Record the length.\n",
        "    train_lengths_en.append(len(train_encoded))\n",
        "    train_labels_en.append(train_labels[i])\n",
        "\n",
        "print('DONE.')\n",
        "print('{:>10,} samples'.format(len(train_lengths_en)))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7517 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing all examples to check sequence lengths...\n",
            "  Tokenized 0 samples.\n",
            "  Tokenized 3,000 samples.\n",
            "  Tokenized 6,000 samples.\n",
            "DONE.\n",
            "     9,000 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2rYlM0W2O8p",
        "outputId": "098883ef-c199-4b14-8365-61fc8fca684e"
      },
      "source": [
        "print('   Min length: {:,} tokens'.format(min(train_lengths_en)))\n",
        "print('   Max length: {:,} tokens'.format(max(train_lengths_en)))\n",
        "print('Median length: {:,} tokens'.format(int(np.median(train_lengths_en))))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Min length: 64 tokens\n",
            "   Max length: 46,300 tokens\n",
            "Median length: 1,168 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "nJc2gu2Z2A2K",
        "outputId": "5e0b8511-f77a-440f-e83d-5872dab8380b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Plot the distribution of comment lengths.\n",
        "sns.distplot(train_lengths_en, kde=False, rug=False)\n",
        "\n",
        "plt.title('Distribution of Sequence Lengths')\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('# of Samples')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "O4Zlus1x2lcZ",
        "outputId": "0e85e1f8-2e8e-4036-d197-93840ecc8c62"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Truncate any comment lengths greater than 512.\n",
        "trunc_lengths = [min(l, 7000) for l in train_lengths_en]\n",
        "\n",
        "# Plot the distribution of comment lengths.\n",
        "sns.distplot(trunc_lengths, kde=False, rug=False)\n",
        "\n",
        "plt.title('Comment Lengths')\n",
        "plt.xlabel('Comment Length')\n",
        "plt.ylabel('# of Comments')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7HRcAvM03_h",
        "outputId": "341c8e0c-adfc-46c0-f724-300f2a87c877"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "train_input_ids = []\n",
        "\n",
        "# Record the length of each sequence (after truncating to 450).\n",
        "train_lengths = []\n",
        "\n",
        "# Get the labels from the DataFrame, and convert from booleans to ints.\n",
        "train_labels = train_bi.unviolated.to_numpy()\n",
        "\n",
        "# Labels after some of the comments are divided into chunks.\n",
        "train_chunk_labels = []\n",
        "\n",
        "print('Tokenizing comments...')\n",
        "\n",
        "# For every sentence...\n",
        "for i, sen in enumerate(train_bi.Fact):\n",
        "    \n",
        "    # Report progress.\n",
        "    if ((len(train_input_ids) % 1000) == 0):\n",
        "        print('  Read {:,} comments.'.format(len(train_input_ids)))\n",
        "    \n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    train_encoded_sent = xlmr_tokenizer.encode(\n",
        "                        sen,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        #max_length = 450,          # Truncate all sentences.                        \n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Get the label for this sentence.\n",
        "    label = train_labels[i]\n",
        "\n",
        "    # If the sentence is too long, chunk it.\n",
        "    if len(train_encoded_sent) > 450:\n",
        "\n",
        "        # Strip off special tokens.\n",
        "        train_encoded_sent = train_encoded_sent[1:-1]\n",
        "        #print('Sentence length:', len(encoded_sent))\n",
        "\n",
        "        # Chunk the sentence, each sentence needs its own CLS and SEP tokens.\n",
        "        chunk_len = 450 - 2\n",
        "\n",
        "        # Make chunks...\n",
        "\n",
        "        # For each starting index...\n",
        "        for j in range(0, len(train_encoded_sent), chunk_len):\n",
        "        \n",
        "            # Make sure the end index doesn't go beyond the list.\n",
        "            #end = min(j+chunk_len, len(encoded_sent) + 1)\n",
        "\n",
        "            # What's the actual chunk length?\n",
        "            #actual_len = end - j\n",
        "\n",
        "            # Select the tokens. Note: Python slicing syntax makes this easier--\n",
        "            # for the last chunk, even if the end index is past the end of the\n",
        "            # list, the slice will just return what's there.\n",
        "            tokens = train_encoded_sent[j:j+chunk_len]\n",
        "\n",
        "            # Add the special tokens.\n",
        "            chunk = [xlmr_tokenizer.cls_token_id] + tokens + [xlmr_tokenizer.sep_token_id]\n",
        "\n",
        "            #print('  ', len(chunk))\n",
        "\n",
        "            # Add the chunk to our encoded sentences.\n",
        "            train_input_ids.append(chunk)\n",
        "\n",
        "            # Give all the chunks the same label.\n",
        "            train_chunk_labels.append(label) \n",
        "    \n",
        "    # Otherwise, just add it to the list.\n",
        "    else:\n",
        "        train_input_ids.append(train_encoded_sent)\n",
        "        train_chunk_labels.append(label)\n",
        "\n",
        "print('DONE.')\n",
        "print('{:>10,} comments before chunking'.format(len(train_bi)))\n",
        "print('{:>10,} comments after chunking'.format(len(train_input_ids)))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing comments...\n",
            "  Read 0 comments.\n",
            "  Read 1,000 comments.\n",
            "  Read 3,000 comments.\n",
            "  Read 5,000 comments.\n",
            "  Read 8,000 comments.\n",
            "  Read 16,000 comments.\n",
            "  Read 17,000 comments.\n",
            "  Read 19,000 comments.\n",
            "  Read 23,000 comments.\n",
            "  Read 36,000 comments.\n",
            "  Read 38,000 comments.\n",
            "DONE.\n",
            "     9,000 comments before chunking\n",
            "    40,744 comments after chunking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "qMnX247J7Ngg",
        "outputId": "5134e691-18cc-4eca-f8fd-d2b32d442be8"
      },
      "source": [
        "# Plot the number of tokens of each length.\n",
        "sns.countplot(train_chunk_labels)\n",
        "\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('# of Training Samples')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frPSYvAe8B1z"
      },
      "source": [
        "The classes are very imbalanced, so we have to be careful interpreting our accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd6xZ4S9CPEo",
        "outputId": "4bdb4fb3-b858-4ea1-8eee-80eff4885319"
      },
      "source": [
        "validation_input_ids = []\n",
        "\n",
        "validation_lengths = []\n",
        "\n",
        "validation_labels = validation_bi.unviolated.to_numpy()\n",
        "\n",
        "validation_chunk_labels = []\n",
        "\n",
        "print('Tokenizing comments...')\n",
        "\n",
        "# For every sentence...\n",
        "for i, sen in enumerate(validation_bi.Fact):\n",
        "    \n",
        "    # Report progress.\n",
        "    if ((len(validation_input_ids) % 1000) == 0):\n",
        "        print('  Read {:,} comments.'.format(len(validation_input_ids)))\n",
        "    \n",
        "    validation_encoded_sent = xlmr_tokenizer.encode(\n",
        "                        sen,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        #max_length = 450,          # Truncate all sentences.                        \n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Get the label for this sentence.\n",
        "    label = validation_labels[i]\n",
        "\n",
        "    # If the sentence is too long, chunk it.\n",
        "    if len(validation_encoded_sent) > 450:\n",
        "\n",
        "        # Strip off special tokens.\n",
        "        validation_encoded_sent = validation_encoded_sent[1:-1]\n",
        "\n",
        "        chunk_len = 450 - 2\n",
        "\n",
        "        # Make chunks...\n",
        "\n",
        "        # For each starting index...\n",
        "        for j in range(0, len(validation_encoded_sent), chunk_len):\n",
        "\n",
        "            tokens = validation_encoded_sent[j:j+chunk_len]\n",
        "\n",
        "            # Add the special tokens.\n",
        "            chunk = [xlmr_tokenizer.cls_token_id] + tokens + [xlmr_tokenizer.sep_token_id]\n",
        "\n",
        "            #print('  ', len(chunk))\n",
        "\n",
        "            # Add the chunk to our encoded sentences.\n",
        "            validation_input_ids.append(chunk)\n",
        "\n",
        "            # Give all the chunks the same label.\n",
        "            validation_chunk_labels.append(label) \n",
        "    \n",
        "    # Otherwise, just add it to the list.\n",
        "    else:\n",
        "        validation_input_ids.append(validation_encoded_sent)\n",
        "        validation_chunk_labels.append(label)\n",
        "\n",
        "print('DONE.')\n",
        "print('{:>10,} facts before chunking'.format(len(validation_bi)))\n",
        "print('{:>10,} facts after chunking'.format(len(validation_input_ids)))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing comments...\n",
            "  Read 0 comments.\n",
            "  Read 2,000 comments.\n",
            "  Read 5,000 comments.\n",
            "DONE.\n",
            "     1,000 comments before chunking\n",
            "     5,048 comments after chunking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73n3G2kR89P2"
      },
      "source": [
        "# The number of samples and number of labels should match.\n",
        "assert(len(train_input_ids) == len(train_chunk_labels))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cANyfgFCHcMD",
        "outputId": "5c47efba-54ab-4026-c68d-2183fac67038"
      },
      "source": [
        "len(train_chunk_labels)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40744"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2kw2DKIDa9R"
      },
      "source": [
        "assert(len(validation_input_ids) == len(validation_chunk_labels))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7mWrklA8_eX",
        "outputId": "a09a8085-e031-46d1-d7b9-533092b07ab6"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the required sequence length.\n",
        "MAX_LEN = 450\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(xlmr_tokenizer.pad_token, xlmr_tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 450 values...\n",
            "\n",
            "Padding token: \"<pad>\", ID: 1\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGrDZrpkEVEh",
        "outputId": "1d9c8290-cfb6-4fad-ee71-7d16f90d139f"
      },
      "source": [
        "# Set the required sequence length.\n",
        "MAX_LEN = 450\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(xlmr_tokenizer.pad_token, xlmr_tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "validation_input_ids = pad_sequences(validation_input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 450 values...\n",
            "\n",
            "Padding token: \"<pad>\", ID: 1\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu9aIZtM-Nbo"
      },
      "source": [
        "# Create attention masks\n",
        "train_attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in train_input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    train_att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    train_attention_masks.append(train_att_mask)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39WRcKlcElKq"
      },
      "source": [
        "# Create attention masks\n",
        "validation_attention_masks = []\n",
        "# For each sentence...\n",
        "for sent in validation_input_ids:    \n",
        "    # Create the attention mask.\n",
        "    validation_att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    # Store the attention mask for this sentence.\n",
        "    validation_attention_masks.append(validation_att_mask)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIKK9uwkCOjM",
        "outputId": "a6d3e2cd-6606-41d6-eec0-04100d4305d9"
      },
      "source": [
        "len(train_chunk_labels)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40744"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrb64neUKxnp"
      },
      "source": [
        "### 3.4. Final Data Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZcaSDWK8EQ"
      },
      "source": [
        "(1) The model expects PyTorch tensors rather than numpy.ndarrays, so convert all the dataset variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN2FUJTuL42W"
      },
      "source": [
        "# Convert each Python list of Tensors into a 2D Tensor matrix.\n",
        "train_input_ids = torch.tensor(train_input_ids)\n",
        "train_attn_masks = torch.tensor(train_attention_masks)\n",
        "validation_input_ids = torch.tensor(validation_input_ids)\n",
        "validation_attn_masks = torch.tensor(validation_attention_masks)\n",
        "train_chunk_labels_tensor = torch.tensor(train_chunk_labels)\n",
        "validation_chunk_labels_tensor = torch.tensor(validation_chunk_labels)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1fZEgCFQZWJ",
        "outputId": "165804f8-d566-4705-fbb7-30a6ff6ddd39"
      },
      "source": [
        "print('\\nData structure shapes:')\n",
        "print('   input_ids:  {:}'.format(str(train_input_ids.shape)))\n",
        "print('  attn_masks:  {:}'.format(str(train_attn_masks.shape)))\n",
        "print('      labels:  {:}'.format(str(train_chunk_labels_tensor.shape)))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data structure shapes:\n",
            "   input_ids:  torch.Size([40744, 450])\n",
            "  attn_masks:  torch.Size([40744, 450])\n",
            "      labels:  torch.Size([40744])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0hk47fJMxuW",
        "outputId": "8e3c86ce-f114-4e6f-d4ca-7517683fc1c6"
      },
      "source": [
        "print('\\nData structure shapes:')\n",
        "print('   input_ids:  {:}'.format(str(validation_input_ids.shape)))\n",
        "print('  attn_masks:  {:}'.format(str(validation_attn_masks.shape)))\n",
        "print('      labels:  {:}'.format(str(validation_chunk_labels_tensor.shape)))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data structure shapes:\n",
            "   input_ids:  torch.Size([5048, 450])\n",
            "  attn_masks:  torch.Size([5048, 450])\n",
            "      labels:  torch.Size([5048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAxC9VSsLKAi"
      },
      "source": [
        "(2) We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60MjEirhLNlD"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, a batch size of 16 or 32 is recommended.\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_input_ids, train_attn_masks, train_chunk_labels_tensor)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_input_ids, validation_attn_masks, validation_chunk_labels_tensor)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN3tyvoxatjO"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(train_input_ids, train_attn_masks, train_chunk_labels_tensor)\n",
        "val_dataset = TensorDataset(validation_input_ids, validation_attn_masks, validation_chunk_labels_tensor)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd1Oiatoa-ju"
      },
      "source": [
        "# Part II - XML RoBerta Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lysE6SeXMtJO"
      },
      "source": [
        "## S4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ4b6j_bMwc_"
      },
      "source": [
        "### 4.1. XLMRobertaForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnknDiXubArd",
        "outputId": "20eb96fe-2eda-4a8f-d5ed-9b0434b2a426"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nyYdYoauLfF"
      },
      "source": [
        "from transformers import XLMRobertaForMaskedLM\n",
        "continue_trained_model = XLMRobertaForMaskedLM.from_pretrained(\"/content/drive/MyDrive/Data/AIjudge/facts_trained\")"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxi7AKCpbI7p"
      },
      "source": [
        "### 4.1. Initialize Model with Pre-Trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkty1HEjbKpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e88b1e8-94b4-42bf-b0d8-520d9a5d8a4b"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification, AdamW\n",
        "# Load XLMRobertaForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "xlmr_model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/Data/AIjudge/facts_en_ch_trained\",\n",
        "    num_labels = 2   # The number of output labels--2 for binary classification. \n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "desc = xlmr_model.cuda()\n",
        "\n",
        "print (\"Model loaded.\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Data/AIjudge/facts_en_ch_trained were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Data/AIjudge/facts_en_ch_trained and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRgu2EfHdVba"
      },
      "source": [
        "### 4.5. Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FoaFToVdjRv"
      },
      "source": [
        "Our `model` object handles the execution of a forward pass, and the calculation of gradients during training. \n",
        "\n",
        "The actual updates to the model's weights, however, are performed by an Optimizer object. Here, we create that object and give it a reference to our model's parameters, as well as set some of our training hyperparameters.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend the following choices of learning rates: 5e-5, 3e-5, 2e-5  (We'll use 2e-5).\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyr_iWeadiHm"
      },
      "source": [
        "With the original BERT model, the authors recommended trying one of the first three of the following learning rates when fine-tuning. We found that a smaller learning rate (5e-6) helped with XLM-R, though.\n",
        "\n",
        "```\n",
        "0.00005  # 5e-5\n",
        "0.00003  # 3e-5\n",
        "0.00002  # 2e-5\n",
        "0.000005 # 5e-6\n",
        "```\n",
        "\n",
        "It'd be worth experimenting more with this value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjaZ2wDYeSd4"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(xlmr_model.parameters(),\n",
        "                  lr = 5e-6, # args.learning_rate\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYgfZmE1ebSz"
      },
      "source": [
        "### 4.6. Epochs & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xi5-jWVefP_"
      },
      "source": [
        "The learning rate scheduler is responsible for updating the learning rate over the course of the training. Generally speaking, you want the learning rate to gradually get smaller and smaller so that training makes gradually finer adjustments to the weights. \n",
        "\n",
        "This decay needs to happen *across all of the training epochs*, so this is where we need to specify the number of epochs we want to train for. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvTdy_-SeSjp"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (BERT authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                      num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                      num_training_steps = total_steps)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYOXqWf2pTTG"
      },
      "source": [
        "**Helper Functions**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpFN9LVzpS1A"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))  "
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqb3PmRmsSoa"
      },
      "source": [
        "def good_update_interval(total_iters, num_desired_updates):\n",
        "    '''\n",
        "    This function will try to pick an intelligent progress update interval \n",
        "    based on the magnitude of the total iterations.\n",
        "\n",
        "    Parameters:\n",
        "      `total_iters` - The number of iterations in the for-loop.\n",
        "      `num_desired_updates` - How many times we want to see an update over the \n",
        "                              course of the for-loop.\n",
        "    '''\n",
        "    # Divide the total iterations by the desired number of updates. Most likely\n",
        "    # this will be some ugly number.\n",
        "    exact_interval = total_iters / num_desired_updates\n",
        "\n",
        "    # The `round` function has the ability to round down a number to, e.g., the\n",
        "    # nearest thousandth: round(exact_interval, -3)\n",
        "    #\n",
        "    # To determine the magnitude to round to, find the magnitude of the total,\n",
        "    # and then go one magnitude below that.\n",
        "\n",
        "    # Get the order of magnitude of the total.\n",
        "    order_of_mag = len(str(total_iters)) - 1\n",
        "\n",
        "    # Our update interval should be rounded to an order of magnitude smaller. \n",
        "    round_mag = order_of_mag - 1\n",
        "\n",
        "    # Round down and cast to an int.\n",
        "    update_interval = int(round(exact_interval, -round_mag))\n",
        "\n",
        "    # Don't allow the interval to be zero!\n",
        "    if update_interval == 0:\n",
        "        update_interval = 1\n",
        "\n",
        "    return update_interval"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ed8tqF5VpQ",
        "outputId": "0032285a-094b-43a7-aa6f-7ec24fdb18e0"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# A quick example...\n",
        "true_labels = [0,1,0,0,1]\n",
        "pred_labels = [0,1,0,0,0]\n",
        "\n",
        "score = roc_auc_score(true_labels, pred_labels, average='macro')\n",
        "\n",
        "print('Example ROC AUC score:', score)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example ROC AUC score: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l9iFSMZshS1"
      },
      "source": [
        "### 4.7. Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slx5RZE_seoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aee55c9-55b6-48b1-d932-f381e067544a"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    xlmr_model.train()\n",
        "\n",
        "    # Pick an interval on which to print progress updates.\n",
        "    update_interval = good_update_interval(\n",
        "                total_iters = len(train_dataloader), \n",
        "                num_desired_updates = 10\n",
        "            )\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update.\n",
        "        if (step % update_interval) == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        xlmr_model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This call returns the loss (because we provided labels) and the \n",
        "        # \"logits\"--the model outputs prior to activation\n",
        "\n",
        "        outputs = xlmr_model(b_input_ids, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(xlmr_model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        " \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    xlmr_model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_loss = 0\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():   \n",
        "   \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = xlmr_model(b_input_ids, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    # Measure validation accuracy...\n",
        "\n",
        "    # Combine the results across all batches. \n",
        "    flat_predictions = np.concatenate(predictions, axis=0)\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "    # For each sample, pick the label (0, 1, or 2) with the highest score.\n",
        "    predicted_labels = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Calculate the validation accuracy.\n",
        "    val_accuracy = (predicted_labels == flat_true_labels).mean()\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch   300  of  2,547.    Elapsed: 0:03:58.\n",
            "  Batch   600  of  2,547.    Elapsed: 0:07:56.\n",
            "  Batch   900  of  2,547.    Elapsed: 0:11:53.\n",
            "  Batch 1,200  of  2,547.    Elapsed: 0:15:51.\n",
            "  Batch 1,500  of  2,547.    Elapsed: 0:19:49.\n",
            "  Batch 1,800  of  2,547.    Elapsed: 0:23:46.\n",
            "  Batch 2,100  of  2,547.    Elapsed: 0:27:44.\n",
            "  Batch 2,400  of  2,547.    Elapsed: 0:31:42.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:33:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:01:21\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch   300  of  2,547.    Elapsed: 0:03:58.\n",
            "  Batch   600  of  2,547.    Elapsed: 0:07:55.\n",
            "  Batch   900  of  2,547.    Elapsed: 0:11:53.\n",
            "  Batch 1,200  of  2,547.    Elapsed: 0:15:51.\n",
            "  Batch 1,500  of  2,547.    Elapsed: 0:19:48.\n",
            "  Batch 1,800  of  2,547.    Elapsed: 0:23:46.\n",
            "  Batch 2,100  of  2,547.    Elapsed: 0:27:44.\n",
            "  Batch 2,400  of  2,547.    Elapsed: 0:31:41.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:33:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:01:21\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch   300  of  2,547.    Elapsed: 0:03:58.\n",
            "  Batch   600  of  2,547.    Elapsed: 0:07:55.\n",
            "  Batch   900  of  2,547.    Elapsed: 0:11:53.\n",
            "  Batch 1,200  of  2,547.    Elapsed: 0:15:51.\n",
            "  Batch 1,500  of  2,547.    Elapsed: 0:19:48.\n",
            "  Batch 1,800  of  2,547.    Elapsed: 0:23:46.\n",
            "  Batch 2,100  of  2,547.    Elapsed: 0:27:44.\n",
            "  Batch 2,400  of  2,547.    Elapsed: 0:31:41.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:33:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:01:21\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:44:56 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLml-mjzS8UP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8400c2f-e962-4366-957f-84cf85c5cc81"
      },
      "source": [
        "12"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8j9avYJS9QX"
      },
      "source": [
        "loss_values = []\n",
        "for epoch in training_stats:\n",
        "  loss_values.append(epoch['Training Loss'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgdEtjJvXvXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "b2b72d1f-21af-438c-a6b7-0338cacf0f9a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pcCo2GgZ5KR"
      },
      "source": [
        "## S5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLjQkhHAZ9oo"
      },
      "source": [
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDVy4tzJaAxq"
      },
      "source": [
        "### 5.1. Tokenize Test Set with Chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Mgs2TyaGOA"
      },
      "source": [
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsgG7e0CaJ8K"
      },
      "source": [
        "**Chunk the Test Samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHYM00WQaCfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e74f12-11bb-49ca-898d-55f1fe9b8809"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "test_input_ids = []\n",
        "\n",
        "# Record the length of each sequence (after truncating to 512).\n",
        "test_lengths = []\n",
        "\n",
        "# Get the labels from the DataFrame, and convert from booleans to ints.\n",
        "test_labels = validation_bi.unviolated.to_numpy()\n",
        "\n",
        "# Labels after some of the comments are divided into chunks.\n",
        "test_chunk_labels = []\n",
        "\n",
        "print('Tokenizing comments...')\n",
        "\n",
        "# Build a Python Dictionary which maps each original test sample to its list of\n",
        "# chunks.\n",
        "orig_to_chunk = {}\n",
        "\n",
        "# For every sentence...\n",
        "for i, sen in enumerate(validation_bi.Fact):\n",
        "    \n",
        "    # Report progress.\n",
        "    if ((len(test_input_ids) % 200) == 0):\n",
        "        print('  Read {:,} facts.'.format(len(test_input_ids)))\n",
        "    \n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    test_encoded_sent = xlmr_tokenizer.encode(\n",
        "                        sen,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        #max_length = 450,          # Truncate all sentences.                        \n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    label = test_labels[i]\n",
        "    # Create the list of chunk indeces for this test sample.\n",
        "    orig_to_chunk[i] = []\n",
        "\n",
        "    # If the sentence is too long, chunk it.\n",
        "    if len(test_encoded_sent) > 450:\n",
        "\n",
        "        # Strip off special tokens.\n",
        "        test_encoded_sent = test_encoded_sent[1:-1]\n",
        "        #print('Sentence length:', len(encoded_sent))\n",
        "\n",
        "        # Specify the length of our chunks..\n",
        "        chunk_len = 450 - 2\n",
        "\n",
        "        # Make chunks...\n",
        "\n",
        "        # For each starting index...\n",
        "        for j in range(0, len(test_encoded_sent), chunk_len):\n",
        "        \n",
        "            # Make sure the end index doesn't go beyond the list.\n",
        "            #end = min(j+chunk_len, len(encoded_sent) + 1)\n",
        "\n",
        "            # What's the actual chunk length?\n",
        "            #actual_len = end - j\n",
        "\n",
        "            # Select the tokens. Note: Python slicing syntax makes this easier--\n",
        "            # for the last chunk, even if the end index is past the end of the\n",
        "            # list, the slice will just return what's there.\n",
        "            tokens = test_encoded_sent[j:j+chunk_len]\n",
        "\n",
        "            # Add the special tokens.\n",
        "            chunk = [xlmr_tokenizer.cls_token_id] + tokens + [xlmr_tokenizer.sep_token_id]\n",
        "\n",
        "            #print('  ', len(chunk))\n",
        "\n",
        "            # Add the chunk to our encoded sentences.\n",
        "            test_input_ids.append(chunk)\n",
        "\n",
        "            test_chunk_labels.append(label) \n",
        "\n",
        "            # Map from the original test sample index to the index of this \n",
        "            # chunk.\n",
        "            orig_to_chunk[i].append(len(test_input_ids) - 1)\n",
        "    \n",
        "    # Otherwise, just add it to the list.\n",
        "    else:\n",
        "        test_input_ids.append(test_encoded_sent)\n",
        "        test_chunk_labels.append(label)\n",
        "\n",
        "        # Map from the original test sample index to the index of its only\n",
        "        # chunk.        \n",
        "        orig_to_chunk[i].append(len(test_input_ids) - 1)\n",
        "\n",
        "print('DONE.')\n",
        "print('{:>10,} comments before chunking'.format(len(validation_bi)))\n",
        "print('{:>10,} comments after chunking'.format(len(test_input_ids)))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing comments...\n",
            "  Read 0 facts.\n",
            "  Read 200 facts.\n",
            "  Read 2,000 facts.\n",
            "  Read 2,400 facts.\n",
            "  Read 2,800 facts.\n",
            "  Read 3,200 facts.\n",
            "  Read 3,800 facts.\n",
            "  Read 4,200 facts.\n",
            "  Read 5,000 facts.\n",
            "DONE.\n",
            "     1,000 comments before chunking\n",
            "     5,048 comments after chunking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riNLOfjo1g1K",
        "outputId": "790a47d4-2cd7-40d1-98bc-d4c6fe53843a"
      },
      "source": [
        "# Also retrieve the labels as a list.\n",
        "\n",
        "# Get the labels from the DataFrame, and convert from booleans to ints.\n",
        "test_labels = validation_bi.unviolated.to_numpy().astype(int)\n",
        "\n",
        "print('{:>10,} positive (unviolated)'.format(np.sum(test_labels)))\n",
        "print('{:>10,} negative (violated)'.format(len(test_labels) - np.sum(test_labels)))\n",
        "\n",
        "# For evaluating the test set, the individual chunk labels don't matter, so\n",
        "# we'll just make the list all zeros.\n",
        "chunk_labels = [0]*len(test_input_ids)\n",
        "\n",
        "# Pad our input tokens\n",
        "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, \n",
        "                               dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "test_attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in test_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  test_attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "test_inputs = torch.tensor(test_input_ids)\n",
        "test_masks = torch.tensor(test_attention_masks)\n",
        "chunk_labels = torch.tensor(chunk_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "test_data = TensorDataset(test_inputs, test_masks, chunk_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         1 positive (unviolated)\n",
            "       999 negative (violated)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kADI9gEGu_gk"
      },
      "source": [
        "### 5.2. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8mWx7F5vA96"
      },
      "source": [
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set.\n",
        "\n",
        "There are no changes required in this cell for chunking--we'll just run all of the chunks through the model and retrieve the logits. Then, in the next section, we'll average together the appropriate outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EafEsHkHuZAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227b351d-625a-42c6-fba1-2cf58f001024"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "xlmr_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Measure elapsed time.\n",
        "t0 = time.time()\n",
        "\n",
        "# Predict \n",
        "for (step, batch) in enumerate(test_dataloader):\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "    # Progress update every 100 batches.\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        # Calculate elapsed time in minutes.\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        # Report progress.\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = xlmr_model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "  \n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 5,048 test sentences...\n",
            "  Batch   100  of    158.    Elapsed: 0:00:49.\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBT-RHCDz9UA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9961d4-609e-4134-ffe0-69500ab2a10e"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH-5_Nu-0T2-"
      },
      "source": [
        "`predictions` has one element per batch. Collapse the batches so we have one continuous list of predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7rtLzSd0N6K"
      },
      "source": [
        "# Combine the results across the batches.\n",
        "predictions_combined = np.concatenate(predictions, axis=0)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bylyEW60i6d"
      },
      "source": [
        "Here are the outputs for the first 5 samples / chunks. There are two columns--the first column is the output of the \"label 0\" (not an attack) classifier head, and the other is the output of the \"label 1\" (contains an attack) classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAXFqHRF4E1r",
        "outputId": "fc8a62c0-6363-4e27-de4a-681fd19312f1"
      },
      "source": [
        "predictions_combined[0:5]"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.7508833, -3.273324 ],\n",
              "       [ 3.9320102, -3.4056349],\n",
              "       [ 3.8050208, -3.3224328],\n",
              "       [ 3.9876876, -3.454502 ],\n",
              "       [ 3.9810042, -3.4482417]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD65HYZ6kBJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feba18eb-df79-4518-dae7-3cbdb8b8d3b5"
      },
      "source": [
        "predictions_combined.shape"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6081, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MbkAfIDJkTX"
      },
      "source": [
        "test_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DMYSgFkPOd0"
      },
      "source": [
        "test_df_labels_onehot.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFIUbD99KsKi"
      },
      "source": [
        "diff_tr_te = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w1v9vPwM8SO"
      },
      "source": [
        "len(train_chunk_mlb.classes_.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvIrMKGxKG-O"
      },
      "source": [
        "predictions_combined_pandas = pd.DataFrame(predictions_combined, columns = train_chunk_mlb.classes_.tolist())\n",
        "predictions_combined_modified = predictions_combined_pandas.drop([diff_tr_te[0]],axis=1)\n",
        "predictions_combined_modified = predictions_combined_modified.drop([diff_tr_te[1]],axis=1)\n",
        "predictions_combined_modified = predictions_combined_modified.drop([diff_tr_te[2]],axis=1)\n",
        "predictions_combined_modified = predictions_combined_modified.drop([diff_tr_te[3]],axis=1)\n",
        "predictions_combined_modified = predictions_combined_modified.drop([diff_tr_te[4]],axis=1)\n",
        "predictions_combined_np = np.array(predictions_combined_modified)\n",
        "predictions_combined_np.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkPaZP3rXArn"
      },
      "source": [
        "predictions_combined_np[6000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVVNsUkOMz-0"
      },
      "source": [
        "\n",
        "    # Calculate the validation accuracy.\n",
        "    #val_accuracy = roc_auc_score(flat_true_labels, flat_predictions, average='macro')\n",
        "test_accuracy = roc_auc_score(flat_true_labels_np, predictions_combined_np, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_XneiL00t8Y"
      },
      "source": [
        "#### Using Only the First Chunk (Sanity Check)\n",
        "\n",
        "As a kind of sanity test, we can use just the predictions on the first chunk of every sample. We'd expect this to achieve close to the same accuracy that we got in the original Notebook, since this is equivalent to just truncating the test samples.\n",
        "\n",
        "The only difference is that in this notebook we had more training samples, because we trained on all of the chunks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7-iN4LDOHZe"
      },
      "source": [
        "len(orig_to_chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HAPaZMkOhx6"
      },
      "source": [
        "len(true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEY1WS1LVfK9"
      },
      "source": [
        "len(p1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow1I8WWVWDUd"
      },
      "source": [
        "test_df_labels_onehot_np = np.array(test_df_labels_onehot)\n",
        "test_df_labels_onehot_np.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-zc40fqkBvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee398ea-7e02-44d7-ff04-f8c7a78ea36b"
      },
      "source": [
        "# Get the labels for the original (unchunked) comments.\n",
        "true_labels = validation_bi.unviolated.to_numpy().astype(int)\n",
        "\n",
        "p1 = []\n",
        "\n",
        "# For each of the original test samples...\n",
        "for test_i in range(0, len(true_labels)):\n",
        "\n",
        "    # `chunk_i` is the index into `predictions` for the first chunk of test \n",
        "    # sample `test_i`.\n",
        "    chunk_i = orig_to_chunk[test_i][0]\n",
        "\n",
        "    # `predictions` has two columns--take the output from the \"label 1\" \n",
        "    # classifier to use for our prediction.\n",
        "    p1.append(predictions_combined[chunk_i, 1])\n",
        "\n",
        "# Calculate the ROC AUC.\n",
        "auc = roc_auc_score(true_labels, p1)\n",
        "\n",
        "print('Test ROC AUC: %.3f' %auc)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ROC AUC: 0.542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7b8fILzI2kf"
      },
      "source": [
        "This is lower than the score we got in the original notebook! There we got 0.969.\n",
        "\n",
        "The only difference (besides the possibility of some randomness...) is that this model was trained on additional samples--the remaining chunks. This suggests to me that these additional chunks may have actually confused the model more than helped it.\n",
        "\n",
        "Let's see how our performance on the test set goes when we average together the scores for the chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrfkUnwoI4B8"
      },
      "source": [
        "#### Averaging Together Chunk Scores\n",
        "\n",
        "Here, for a given *original* (full-text) test sample, we'll select the outputs for all of its chunks, and average them together for our prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVL4pg-RJKou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d97fca-8c79-46ea-b233-21bac71768c1"
      },
      "source": [
        "# Get the labels for the original (unchunked) comments.\n",
        "true_labels = validation_bi.unviolated.to_numpy().astype(int)\n",
        "p2 = []\n",
        "\n",
        "# For each of the original test samples...\n",
        "for test_i in range(0, len(true_labels)):\n",
        "\n",
        "    # `chunk_indeces` is the list of indeces in `predictions` of the chunks for\n",
        "    # sample `test_i`.\n",
        "    chunk_indeces = orig_to_chunk[test_i]\n",
        "\n",
        "    # Select the outputs of the \"label 1\" classifier for all chunks\n",
        "    chunks_outputs = predictions_combined[chunk_indeces,1]\n",
        "\n",
        "    # Average them and use this as the prediction.\n",
        "    p2.append(np.mean(chunks_outputs))\n",
        "\n",
        "# Calculate the ROC AUC.\n",
        "auc = roc_auc_score(true_labels, p2)\n",
        "\n",
        "print('Test ROC AUC: %.3f' %auc)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ROC AUC: 0.554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhHRmHfBZNES"
      },
      "source": [
        "ch = orig_to_chunk[500]\n",
        "ch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrTQQvUJZaAv"
      },
      "source": [
        "predictions_combined_np[ch].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g_NDQ5jaLSp"
      },
      "source": [
        "np.mean(predictions_combined_np[ch], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm0vr40oP2AG"
      },
      "source": [
        "## S6. Save Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwWGuzGZP5Z-"
      },
      "source": [
        "### 6.1. Saving to Disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mKYB_2FP6S9"
      },
      "source": [
        "This first cell (taken from `run_glue.py` [here](https://github.com/huggingface/transformers/blob/35ff345fc9df9e777b27903f11fa213e4052595b/examples/run_glue.py#L495)) writes the model and tokenizer out to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-0sMerDP1M1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa8df5e-46f9-4c8b-afe0-9ab57cd44137"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "output_dir = './model_save_binary/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = xlmr_model.module if hasattr(xlmr_model, 'module') else xlmr_model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "xlmr_tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save_binary/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save_binary/tokenizer_config.json',\n",
              " './model_save_binary/special_tokens_map.json',\n",
              " './model_save_binary/sentencepiece.bpe.model',\n",
              " './model_save_binary/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2Wy-PTJQKMB"
      },
      "source": [
        "### 6.2. Backing Up to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CULWxPeQOUJ"
      },
      "source": [
        "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QPuhI5cQSP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5892a5f8-c181-4e99-86d9-88ab826655f7"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d80hyQfQTQq"
      },
      "source": [
        "gdrive_path = \"/content/drive/MyDrive/model_save_binary\"\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(gdrive_path):\n",
        "    os.makedirs(gdrive_path)\n",
        "\n",
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save_binary/ \"/content/drive/MyDrive/model_save_binary\""
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeBqsFI5QoeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e00220-9446-4c77-ea46-5c6a2cf60182"
      },
      "source": [
        "!ls -l \"/content/drive/MyDrive/model_save_binary\""
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwx------ 2 root root 4096 Sep  4 03:48 model_save\n",
            "drwx------ 2 root root 4096 Sep  4 03:53 model_save_binary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCHZy6x77EzN"
      },
      "source": [
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/model_save_binary/model_save_binary\",\n",
        "    num_labels = 2   # The number of output labels--2 for binary classification. \n",
        ")"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYKkFV9m8guu",
        "outputId": "f743a655-6787-4959-e1ce-583ae6834727"
      },
      "source": [
        "model"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5HlA-DC8hpI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}